<html contenteditable=""><head>
<meta http-equiv="content-type" content="text/html; charset=windows-1252"></head><body><b>Statistical inference</b> is the process of deducing properties of an underlying <a href="https://en.wikipedia.org/wiki/Probability_distribution" title="Probability distribution">distribution</a> by analysis of data.&nbsp;  Inferential statistical analysis infers properties about a population: 
this includes testing hypotheses and deriving estimates. The population 
is assumed to be larger than the observed data set; in other words, the 
observed data is assumed to be <a href="https://en.wikipedia.org/wiki/Sampling_%28statistics%29" title="Sampling (statistics)">sampled</a> from a larger population.<br><br>Statistical inference makes propositions about a population, using data drawn from the population with some form of <a href="https://en.wikipedia.org/wiki/Sampling_%28statistics%29" title="Sampling (statistics)">sampling</a>. Given a hypothesis about a population, for which we wish to draw inferences, statistical inference consists of (firstly) <a href="https://en.wikipedia.org/wiki/Model_selection" title="Model selection">selecting</a> a <a href="https://en.wikipedia.org/wiki/Statistical_model" title="Statistical model">statistical model</a> of the process that generates the data and (secondly) deducing propositions from the model.<br><br>-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------<br><p>The <a href="https://en.wikipedia.org/wiki/Logical_consequence" title="Logical consequence">conclusion</a> of a <b>statistical inference</b> is a statistical <a href="https://en.wikipedia.org/wiki/Proposition" title="Proposition">proposition</a>.<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;"><i><a href="https://en.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (February 2012)"></span></a></i></sup>Some common forms of statistical proposition are the following:</p>
<ul><li>a <a href="https://en.wikipedia.org/wiki/Point_estimate" title="Point estimate" class="mw-redirect">point estimate</a>, i.e. a particular value that best approximates some parameter of interest;</li><li>an <a href="https://en.wikipedia.org/wiki/Interval_estimate" title="Interval estimate" class="mw-redirect">interval estimate</a>, e.g. a <a href="https://en.wikipedia.org/wiki/Confidence_interval" title="Confidence interval">confidence interval</a>
 (or set estimate), i.e. an interval constructed using a dataset drawn 
from a population so that, under repeated sampling of such datasets, 
such intervals would contain the true parameter value with the <a href="https://en.wikipedia.org/wiki/Frequency_probability" title="Frequency probability" class="mw-redirect">probability</a> at the stated <a href="https://en.wikipedia.org/wiki/Confidence_level" title="Confidence level" class="mw-redirect">confidence level</a>;</li><li>a <a href="https://en.wikipedia.org/wiki/Credible_intervals" title="Credible intervals" class="mw-redirect">credible interval</a>, i.e. a set of values containing, for example, 95% of posterior belief;</li><li>rejection of a <a href="https://en.wikipedia.org/wiki/Statistical_hypothesis_testing" title="Statistical hypothesis testing">hypothesis</a>;<sup id="cite_ref-4" class="reference"><a href="https://en.wikipedia.org/wiki/Statistical_inference#cite_note-4"><span></span><span></span></a></sup></li><li><a href="https://en.wikipedia.org/wiki/Cluster_analysis" title="Cluster analysis">clustering</a> or <a href="https://en.wikipedia.org/wiki/Statistical_classification" title="Statistical classification">classification</a> of data points into groups.</li></ul><br>=================================================================================================================================================<br><br>In <a href="https://en.wikipedia.org/wiki/Probability_and_statistics" title="Probability and statistics">probability and statistics</a>, a <b>probability distribution</b> assigns a <a href="https://en.wikipedia.org/wiki/Probability" title="Probability">probability</a> to each <a href="https://en.wikipedia.org/wiki/Measure_%28mathematics%29" title="Measure (mathematics)">measurable subset</a> of the possible outcomes of a random <a href="https://en.wikipedia.org/wiki/Experiment_%28probability_theory%29" title="Experiment (probability theory)">experiment</a>, <a href="https://en.wikipedia.org/wiki/Survey_methodology" title="Survey methodology">survey</a>, or procedure of <a href="https://en.wikipedia.org/wiki/Statistical_inference" title="Statistical inference">statistical inference</a>.<br><br>To define probability distributions for the simplest cases, one needs to distinguish between <b>discrete</b> and <b>continuous</b> <a href="https://en.wikipedia.org/wiki/Random_variable" title="Random variable">random variables</a>. In the discrete case, one can easily assign a probability to each possible value: for example, when throwing a fair <a href="https://en.wikipedia.org/wiki/Dice" title="Dice">die</a>, each of the six values <i>1</i> to <i>6</i>
 has the probability 1/6. In contrast, when a random variable takes 
values from a continuum then, typically, probabilities can be nonzero 
only if they refer to intervals: in quality control one might demand 
that the probability of a "500&nbsp;g" package containing between 490&nbsp;g and 
510&nbsp;g should be no less than 98%.<br><br><h2><span class="mw-headline" id="Terminology">Terminology</span></h2>
<p>As probability theory is used in quite diverse applications, 
terminology is not uniform and sometimes confusing. The following terms 
are used for non-cumulative probability distribution functions:</p>
<ul><li><b>Probability mass</b>, <a href="https://en.wikipedia.org/wiki/Probability_mass_function" title="Probability mass function">Probability mass function</a>, <b>p.m.f.</b>: for discrete random variables.</li><li><a href="https://en.wikipedia.org/wiki/Categorical_distribution" title="Categorical distribution">Categorical distribution</a>: for discrete random variables with a finite set of values.</li><li><b>Probability density</b>, <a href="https://en.wikipedia.org/wiki/Probability_density_function" title="Probability density function">Probability density function</a>, <b>p.d.f.</b>: most often reserved for continuous random variables.</li></ul>
<p>The following terms are somewhat ambiguous as they can refer to 
non-cumulative or cumulative distributions, depending on authors' 
preferences:</p>
<ul><li><b>Probability distribution function</b>: continuous or discrete, non-cumulative or <a href="https://en.wikipedia.org/wiki/Cumulative_distribution_function" title="Cumulative distribution function">cumulative</a>.</li><li><b>Probability function</b>: even more ambiguous, can mean any of the above or other things.</li></ul>
<p>Finally,</p>
<ul><li><b>Probability distribution</b>: sometimes the same as <i>probability distribution function</i>,
 but usually refers to the more complete assignment of probabilities to 
all measurable subsets of outcomes, not just to specific outcomes or 
ranges of outcomes.</li></ul>
<h3><span class="mw-headline" id="Basic_terms">Basic terms</span></h3>
<ul><li><a href="https://en.wikipedia.org/wiki/Mode_%28statistics%29" title="Mode (statistics)">Mode</a>:
 for a discrete random variable, the value with highest probability (the
 location at which the probability mass function has its peak); for a 
continuous random variable, the location at which the probability 
density function has its peak.</li><li><a href="https://en.wikipedia.org/wiki/Support_%28mathematics%29" title="Support (mathematics)">Support</a>: the smallest closed set whose <a href="https://en.wikipedia.org/wiki/Complement_%28set_theory%29" title="Complement (set theory)">complement</a> has probability zero.</li><li><a href="https://en.wikipedia.org/wiki/Heavy-tailed_distribution" title="Heavy-tailed distribution">Head</a>: the range of values where the pmf or pdf is relatively high.</li><li><a href="https://en.wikipedia.org/wiki/Heavy-tailed_distribution" title="Heavy-tailed distribution">Tail</a>: the complement of the head within the support; the large set of values where the pmf or pdf is relatively low.</li><li><a href="https://en.wikipedia.org/wiki/Expected_value" title="Expected value">Expected value</a> or <b>mean</b>: the <a href="https://en.wikipedia.org/wiki/Weighted_average" title="Weighted average" class="mw-redirect">weighted average</a> of the possible values, using their probabilities as their weights; or the continuous analog thereof.</li><li><a href="https://en.wikipedia.org/wiki/Median" title="Median">Median</a>: the value such that the set of values less than the median has a probability of one-half.</li><li><a href="https://en.wikipedia.org/wiki/Variance" title="Variance">Variance</a>: the second moment of the pmf or pdf about the mean; an important measure of the <a href="https://en.wikipedia.org/wiki/Statistical_dispersion" title="Statistical dispersion">dispersion</a> of the distribution.</li><li><a href="https://en.wikipedia.org/wiki/Standard_deviation" title="Standard deviation">Standard deviation</a>: the square root of the variance, and hence another measure of dispersion.</li><li><b>Symmetry</b>: a property of some distributions in which the 
portion of the distribution to the left of a specific value is a mirror 
image of the portion to its right.</li><li><a href="https://en.wikipedia.org/wiki/Skewness" title="Skewness">Skewness</a>: a measure of the extent to which a pmf or pdf "leans" to one side of its mean.</li></ul><p>----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------<br></p>A <b>discrete probability distribution</b> is a <i>probability distribution</i> characterized by a <a href="https://en.wikipedia.org/wiki/Probability_mass_function" title="Probability mass function">probability mass function</a>. Thus, the distribution of a <a href="https://en.wikipedia.org/wiki/Random_variable" title="Random variable">random variable</a> <i>X</i> is discrete, and <i>X</i> is called a <b>discrete random variable</b>, if
<dl><dd><img class="mwe-math-fallback-image-inline tex" alt="\sum_u \Pr(X=u) = 1" src="StatisticalInference_files/d82378b0a5d71745e4ac7d7b18cb4fd0.png">as <i>u</i> runs through the set of all possible values of <i>X</i>. Hence, a random variable can assume only a <a href="https://en.wikipedia.org/wiki/Finite_set" title="Finite set">finite</a> or <a href="https://en.wikipedia.org/wiki/Countable" title="Countable" class="mw-redirect">countably infinite</a> number of values—the random variable is a <a href="https://en.wikipedia.org/wiki/Discrete_variable" title="Discrete variable" class="mw-redirect">discrete variable</a>.
 For the number of potential values to be countably infinite, even 
though their probabilities sum to 1, the probabilities have to decline 
to zero fast enough.</dd><dt><br></dt><dt>Well-known discrete probability distributions used in statistical modeling include the <a href="https://en.wikipedia.org/wiki/Poisson_distribution" title="Poisson distribution">Poisson distribution</a>, the <a href="https://en.wikipedia.org/wiki/Bernoulli_distribution" title="Bernoulli distribution">Bernoulli distribution</a>, the <a href="https://en.wikipedia.org/wiki/Binomial_distribution" title="Binomial distribution">binomial distribution</a>, the <a href="https://en.wikipedia.org/wiki/Geometric_distribution" title="Geometric distribution">geometric distribution</a>, and the <a href="https://en.wikipedia.org/wiki/Negative_binomial_distribution" title="Negative binomial distribution">negative binomial distribution</a>. Additionally, the <a href="https://en.wikipedia.org/wiki/Uniform_distribution_%28discrete%29" title="Uniform distribution (discrete)">discrete uniform distribution</a> is commonly used in computer programs that make equal-probability random selections between a number of choices.</dt></dl>A <b>continuous probability distribution</b> is a <i>probability distribution</i> that has a <a href="https://en.wikipedia.org/wiki/Probability_density_function" title="Probability density function">probability density function</a>. Mathematicians also call such a distribution <b>absolutely continuous</b>, since its <a href="https://en.wikipedia.org/wiki/Cumulative_distribution_function" title="Cumulative distribution function">cumulative distribution function</a> is <a href="https://en.wikipedia.org/wiki/Absolute_continuity" title="Absolute continuity">absolutely continuous</a> with respect to the <a href="https://en.wikipedia.org/wiki/Lebesgue_measure" title="Lebesgue measure">Lebesgue measure</a> <i>&#955;</i>. If the distribution of <i>X</i> is continuous, then <i>X</i> is called a <b>continuous random variable</b>. There are many examples of continuous probability distributions: <a href="https://en.wikipedia.org/wiki/Normal_distribution" title="Normal distribution">normal</a>, <a href="https://en.wikipedia.org/wiki/Uniform_distribution_%28continuous%29" title="Uniform distribution (continuous)">uniform</a>, <a href="https://en.wikipedia.org/wiki/Chi-squared_distribution" title="Chi-squared distribution">chi-squared</a>, and <a href="https://en.wikipedia.org/wiki/List_of_probability_distributions#Continuous_distributions" title="List of probability distributions">others</a>.<br><p>----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------<br></p>The probability distribution of the sum of two independent random variables is the <b><a href="https://en.wikipedia.org/wiki/Convolution" title="Convolution">convolution</a></b> of each of their distributions.<br><br>A frequent problem in statistical simulations (the <a href="https://en.wikipedia.org/wiki/Monte_Carlo_method" title="Monte Carlo method">Monte Carlo method</a>) is the generation of <a href="https://en.wikipedia.org/wiki/Pseudorandomness" title="Pseudorandomness">pseudo-random numbers</a> that are distributed in a given way. Most algorithms are based on a <a href="https://en.wikipedia.org/wiki/Pseudorandom_number_generator" title="Pseudorandom number generator">pseudorandom number generator</a> that produces numbers <i>X</i> that are uniformly distributed in the interval [0,1). These <a href="https://en.wikipedia.org/wiki/Random_variate" title="Random variate">random variates</a> <i>X</i> are then transformed via some algorithm to create a new random variate having the required probability distribution.<br><p>----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------<br></p><br><h2><span class="mw-headline" id="Applications">Applications</span></h2>
<p>The concept of the probability distribution and the random variables 
which they describe underlies the mathematical discipline of probability
 theory, and the science of statistics. There is spread or variability 
in almost any value that can be measured in a population (e.g. height of
 people, durability of a metal, sales growth, traffic flow, etc.); 
almost all measurements are made with some intrinsic error; in physics 
many processes are described probabilistically,from the <a href="https://en.wikipedia.org/wiki/Kinetic_theory" title="Kinetic theory">kinetic properties of gases</a> to the <a href="https://en.wikipedia.org/wiki/Quantum_mechanical" title="Quantum mechanical" class="mw-redirect">quantum mechanical</a> description of <a href="https://en.wikipedia.org/wiki/Fundamental_particles" title="Fundamental particles" class="mw-redirect">fundamental particles</a>. For these and many other reasons, simple <a href="https://en.wikipedia.org/wiki/Number" title="Number">numbers</a> are often inadequate for describing a quantity, while probability distributions are often more appropriate.</p><h3><span class="mw-headline" id="Related_to_real-valued_quantities_that_grow_linearly_.28e.g._errors.2C_offsets.29">Related to real-valued quantities that grow linearly (e.g. errors, offsets)</span></h3>
<ul><li><a href="https://en.wikipedia.org/wiki/Normal_distribution" title="Normal distribution">Normal distribution</a> (Gaussian distribution), for a single such quantity; the most common continuous distribution</li></ul>
<h3><span class="mw-headline" id="Related_to_positive_real-valued_quantities_that_grow_exponentially_.28e.g._prices.2C_incomes.2C_populations.29">Related to positive real-valued quantities that grow exponentially (e.g. prices, incomes, populations)</span></h3>
<ul><li><a href="https://en.wikipedia.org/wiki/Log-normal_distribution" title="Log-normal distribution">Log-normal distribution</a>, for a single such quantity whose log is <a href="https://en.wikipedia.org/wiki/Normal_distribution" title="Normal distribution">normally</a> distributed</li><li><a href="https://en.wikipedia.org/wiki/Pareto_distribution" title="Pareto distribution">Pareto distribution</a>, for a single such quantity whose log is <a href="https://en.wikipedia.org/wiki/Exponential_distribution" title="Exponential distribution">exponentially</a> distributed; the prototypical <a href="https://en.wikipedia.org/wiki/Power_law" title="Power law">power law</a> distribution</li></ul>
<h3><span class="mw-headline" id="Related_to_real-valued_quantities_that_are_assumed_to_be_uniformly_distributed_over_a_.28possibly_unknown.29_region">Related to real-valued quantities that are assumed to be uniformly distributed over a (possibly unknown) region</span></h3>
<ul><li><a href="https://en.wikipedia.org/wiki/Discrete_uniform_distribution" title="Discrete uniform distribution" class="mw-redirect">Discrete uniform distribution</a>, for a finite set of values (e.g. the outcome of a fair die)</li><li><a href="https://en.wikipedia.org/wiki/Continuous_uniform_distribution" title="Continuous uniform distribution" class="mw-redirect">Continuous uniform distribution</a>, for continuously distributed values</li></ul>
<h3><span class="mw-headline" id="Related_to_Bernoulli_trials_.28yes.2Fno_events.2C_with_a_given_probability.29">Related to Bernoulli trials (yes/no events, with a given probability)</span></h3>
<ul><li>Basic distributions:
<ul><li><a href="https://en.wikipedia.org/wiki/Bernoulli_distribution" title="Bernoulli distribution">Bernoulli distribution</a>, for the outcome of a single Bernoulli trial (e.g. success/failure, yes/no)</li><li><a href="https://en.wikipedia.org/wiki/Binomial_distribution" title="Binomial distribution">Binomial distribution</a>, for the number of "positive occurrences" (e.g. successes, yes votes, etc.) given a fixed total number of <a href="https://en.wikipedia.org/wiki/Independent_%28statistics%29" title="Independent (statistics)" class="mw-redirect">independent</a> occurrences</li><li><a href="https://en.wikipedia.org/wiki/Negative_binomial_distribution" title="Negative binomial distribution">Negative binomial distribution</a>,
 for binomial-type observations but where the quantity of interest is 
the number of failures before a given number of successes occurs</li><li><a href="https://en.wikipedia.org/wiki/Geometric_distribution" title="Geometric distribution">Geometric distribution</a>,
 for binomial-type observations but where the quantity of interest is 
the number of failures before the first success; a special case of the <a href="https://en.wikipedia.org/wiki/Negative_binomial_distribution" title="Negative binomial distribution">negative binomial distribution</a></li></ul>
</li><li>Related to sampling schemes over a finite population:
<ul><li><a href="https://en.wikipedia.org/wiki/Hypergeometric_distribution" title="Hypergeometric distribution">Hypergeometric distribution</a>, for the number of "positive occurrences" (e.g. successes, yes votes, etc.) given a fixed number of total occurrences, using <a href="https://en.wikipedia.org/wiki/Sampling_without_replacement" title="Sampling without replacement" class="mw-redirect">sampling without replacement</a></li><li><a href="https://en.wikipedia.org/wiki/Beta-binomial_distribution" title="Beta-binomial distribution">Beta-binomial distribution</a>,
 for the number of "positive occurrences" (e.g. successes, yes votes, 
etc.) given a fixed number of total occurrences, sampling using a <a href="https://en.wikipedia.org/wiki/Polya_urn_scheme" title="Polya urn scheme" class="mw-redirect">Polya urn scheme</a> (in some sense, the "opposite" of <a href="https://en.wikipedia.org/wiki/Sampling_without_replacement" title="Sampling without replacement" class="mw-redirect">sampling without replacement</a>)</li></ul>
</li></ul>
<h3><span class="mw-headline" id="Related_to_categorical_outcomes_.28events_with_K_possible_outcomes.2C_with_a_given_probability_for_each_outcome.29">Related to categorical outcomes (events with <i>K</i> possible outcomes, with a given probability for each outcome)</span></h3>
<ul><li><a href="https://en.wikipedia.org/wiki/Categorical_distribution" title="Categorical distribution">Categorical distribution</a>, for a single categorical outcome (e.g. yes/no/maybe in a survey); a generalization of the <a href="https://en.wikipedia.org/wiki/Bernoulli_distribution" title="Bernoulli distribution">Bernoulli distribution</a></li><li><a href="https://en.wikipedia.org/wiki/Multinomial_distribution" title="Multinomial distribution">Multinomial distribution</a>, for the number of each type of categorical outcome, given a fixed number of total outcomes; a generalization of the <a href="https://en.wikipedia.org/wiki/Binomial_distribution" title="Binomial distribution">binomial distribution</a></li><li><a href="https://en.wikipedia.org/wiki/Multivariate_hypergeometric_distribution" title="Multivariate hypergeometric distribution" class="mw-redirect">Multivariate hypergeometric distribution</a>, similar to the <a href="https://en.wikipedia.org/wiki/Multinomial_distribution" title="Multinomial distribution">multinomial distribution</a>, but using <a href="https://en.wikipedia.org/wiki/Sampling_without_replacement" title="Sampling without replacement" class="mw-redirect">sampling without replacement</a>; a generalization of the <a href="https://en.wikipedia.org/wiki/Hypergeometric_distribution" title="Hypergeometric distribution">hypergeometric distribution</a></li></ul>
<h3><span class="mw-headline" id="Related_to_events_in_a_Poisson_process_.28events_that_occur_independently_with_a_given_rate.29">Related to events in a Poisson process (events that occur independently with a given rate)</span></h3>
<ul><li><a href="https://en.wikipedia.org/wiki/Poisson_distribution" title="Poisson distribution">Poisson distribution</a>, for the number of occurrences of a Poisson-type event in a given period of time</li><li><a href="https://en.wikipedia.org/wiki/Exponential_distribution" title="Exponential distribution">Exponential distribution</a>, for the time before the next Poisson-type event occurs</li><li><a href="https://en.wikipedia.org/wiki/Gamma_distribution" title="Gamma distribution">Gamma distribution</a>, for the time before the next k Poisson-type events occur</li></ul>
<h3><span class="mw-headline" id="Related_to_the_absolute_values_of_vectors_with_normally_distributed_components">Related to the absolute values of vectors with normally distributed components</span></h3>
<ul><li><a href="https://en.wikipedia.org/wiki/Rayleigh_distribution" title="Rayleigh distribution">Rayleigh distribution</a>,
 for the distribution of vector magnitudes with Gaussian distributed 
orthogonal components. Rayleigh distributions are found in RF signals 
with Gaussian real and imaginary components.</li><li><a href="https://en.wikipedia.org/wiki/Rice_distribution" title="Rice distribution">Rice distribution</a>, a generalization of the Rayleigh distributions for where there is a stationary background signal component. Found in <a href="https://en.wikipedia.org/wiki/Rician_fading" title="Rician fading">Rician fading</a> of radio signals due to multipath propagation and in MR images with noise corruption on non-zero NMR signals.</li></ul>
<h3><span class="mw-headline" id="Related_to_normally_distributed_quantities_operated_with_sum_of_squares_.28for_hypothesis_testing.29">Related to normally distributed quantities operated with sum of squares (for hypothesis testing)</span></h3>
<ul><li><a href="https://en.wikipedia.org/wiki/Chi-squared_distribution" title="Chi-squared distribution">Chi-squared distribution</a>, the distribution of a sum of squared <a href="https://en.wikipedia.org/wiki/Standard_normal" title="Standard normal" class="mw-redirect">standard normal</a> variables; useful e.g. for inference regarding the <a href="https://en.wikipedia.org/wiki/Sample_variance" title="Sample variance" class="mw-redirect">sample variance</a> of normally distributed samples (see <a href="https://en.wikipedia.org/wiki/Chi-squared_test" title="Chi-squared test">chi-squared test</a>)</li><li><a href="https://en.wikipedia.org/wiki/Student%27s_t_distribution" title="Student's t distribution" class="mw-redirect">Student's t distribution</a>, the distribution of the ratio of a <a href="https://en.wikipedia.org/wiki/Standard_normal" title="Standard normal" class="mw-redirect">standard normal</a> variable and the square root of a scaled <a href="https://en.wikipedia.org/wiki/Chi_squared_distribution" title="Chi squared distribution" class="mw-redirect">chi squared</a> variable; useful for inference regarding the <a href="https://en.wikipedia.org/wiki/Mean" title="Mean">mean</a> of normally distributed samples with unknown variance (see <a href="https://en.wikipedia.org/wiki/Student%27s_t-test" title="Student's t-test">Student's t-test</a>)</li><li><a href="https://en.wikipedia.org/wiki/F-distribution" title="F-distribution">F-distribution</a>, the distribution of the ratio of two scaled <a href="https://en.wikipedia.org/wiki/Chi_squared_distribution" title="Chi squared distribution" class="mw-redirect">chi squared</a> variables; useful e.g. for inferences that involve comparing variances or involving <a href="https://en.wikipedia.org/wiki/R-squared" title="R-squared" class="mw-redirect">R-squared</a> (the squared <a href="https://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient" title="Pearson product-moment correlation coefficient">correlation coefficient</a>)</li></ul>
<h3><span class="mw-headline" id="Useful_as_conjugate_prior_distributions_in_Bayesian_inference">Useful as conjugate prior distributions in Bayesian inference</span></h3>
<div class="hatnote relarticle mainarticle">Main article: <a href="https://en.wikipedia.org/wiki/Conjugate_prior" title="Conjugate prior">Conjugate prior</a></div>
<ul><li><a href="https://en.wikipedia.org/wiki/Beta_distribution" title="Beta distribution">Beta distribution</a>, for a single probability (real number between 0 and 1); conjugate to the <a href="https://en.wikipedia.org/wiki/Bernoulli_distribution" title="Bernoulli distribution">Bernoulli distribution</a> and <a href="https://en.wikipedia.org/wiki/Binomial_distribution" title="Binomial distribution">binomial distribution</a></li><li><a href="https://en.wikipedia.org/wiki/Gamma_distribution" title="Gamma distribution">Gamma distribution</a>, for a non-negative scaling parameter; conjugate to the rate parameter of a <a href="https://en.wikipedia.org/wiki/Poisson_distribution" title="Poisson distribution">Poisson distribution</a> or <a href="https://en.wikipedia.org/wiki/Exponential_distribution" title="Exponential distribution">exponential distribution</a>, the <a href="https://en.wikipedia.org/wiki/Precision_%28statistics%29" title="Precision (statistics)">precision</a> (inverse <a href="https://en.wikipedia.org/wiki/Variance" title="Variance">variance</a>) of a <a href="https://en.wikipedia.org/wiki/Normal_distribution" title="Normal distribution">normal distribution</a>, etc.</li><li><a href="https://en.wikipedia.org/wiki/Dirichlet_distribution" title="Dirichlet distribution">Dirichlet distribution</a>, for a vector of probabilities that must sum to 1; conjugate to the <a href="https://en.wikipedia.org/wiki/Categorical_distribution" title="Categorical distribution">categorical distribution</a> and <a href="https://en.wikipedia.org/wiki/Multinomial_distribution" title="Multinomial distribution">multinomial distribution</a>; generalization of the <a href="https://en.wikipedia.org/wiki/Beta_distribution" title="Beta distribution">beta distribution</a></li><li><a href="https://en.wikipedia.org/wiki/Wishart_distribution" title="Wishart distribution">Wishart distribution</a>, for a symmetric <a href="https://en.wikipedia.org/wiki/Non-negative_definite" title="Non-negative definite" class="mw-redirect">non-negative definite</a> matrix; conjugate to the inverse of the <a href="https://en.wikipedia.org/wiki/Covariance_matrix" title="Covariance matrix">covariance matrix</a> of a <a href="https://en.wikipedia.org/wiki/Multivariate_normal_distribution" title="Multivariate normal distribution">multivariate normal distribution</a>; generalization of the <a href="https://en.wikipedia.org/wiki/Gamma_distribution" title="Gamma distribution">gamma distribution</a></li></ul><p><br></p></body></html>
